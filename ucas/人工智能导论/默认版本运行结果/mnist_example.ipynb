{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用MoXing实现手写数字图像识别应用\n",
    "\n",
    "  &#160;&#160;本内容主要介绍，如何使用MoXing实现手写数字图像的训练、测试应用。  \n",
    "  \n",
    "### [1. 准备数据](#data_prepare)\n",
    "### [2. 训练模型](#train)\n",
    "### [3. 预测](#predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## <a name=\"data_prepare\">1. 准备数据</a>  \n",
    "  &#160;&#160;从obs的mnist桶的mnist_data对象中下载MNIST数据集，并上传至私有的OBS桶中。\n",
    "  \n",
    "1.1 &#160; &#160; 下载MNIST数据集， 数据集文件说明如下：\n",
    "- t10k-images-idx3-ubyte.gz：验证集，共包含10000个样本。\n",
    "- t10k-labels-idx1-ubyte.gz：验证集标签，共包含10000个样本的类别标签。\n",
    "- train-images-idx3-ubyte.gz：训练集，共包含60000个样本。\n",
    "- train-labels-idx1-ubyte.gz：训练集标签，共包含60000个样本的类别标签。\n",
    "\n",
    "1.2 &#160; &#160; .gz数据无需解压，分别上传至华为云OBS桶 ,该数据路径将设置为data_url。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"train\">2. 训练模型</a>  \n",
    "\n",
    "  &#160;&#160;通过import加载moxing的tensorflow模块 moxing.tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using MoXing-v1.14.0-3c8d0e90\n",
      "INFO:root:Using OBS-Python-SDK-3.1.2\n",
      "INFO:tensorflow:Using TensorFlow-b'v1.13.1-0-g6612da8951'\n"
     ]
    }
   ],
   "source": [
    "import moxing.tensorflow as mox\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据数据存储和数据输出设置data_url和train_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### your coding place： begin  ###########\n",
    "# 此处必须修改为用户数据桶位置\n",
    "\n",
    "#数据在OBS的存储位置。\n",
    "# eg. s3:// ：统一路径输入\n",
    "#     /uBucket ：桶名，用户的私有桶的名称 eg. bucket\n",
    "#     /notebook/data/： 文件路径\n",
    "# 参考网址：https://github.com/huaweicloud/ModelArts-Lab/blob/master/official_examples/docs/%E4%BD%BF%E7%94%A8Notebook%E5%AE%9E%E7%8E%B0%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB.md\n",
    "data_url = 's3://qyt-mnist-data/dataset-mnist/' \n",
    "\n",
    "####### your coding place： end  ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_url = './cache/log/'          #训练输出位置。\n",
    "if not mox.file.exists(data_url):\n",
    "    raise ValueError('Plese verify your data url!')\n",
    "if mox.file.exists(train_url):\n",
    "    mox.file.remove(train_url,recursive=True)\n",
    "mox.file.make_dirs(train_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 通过mox 能够将数据拷贝到本地，这样能够加快训练。操作如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t10k-labels-idx1-ubyte',\n",
       " 't10k-images-idx3-ubyte.gz',\n",
       " 't10k-labels-idx1-ubyte.gz',\n",
       " 'Mnist-Data-Set.zip',\n",
       " 't10k-images-idx3-ubyte',\n",
       " 'test.jpg',\n",
       " 'train-labels-idx1-ubyte',\n",
       " 'train-labels-idx1-ubyte.gz',\n",
       " 'train-images-idx3-ubyte.gz',\n",
       " 'train-images-idx3-ubyte']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 本地创建数据存储文件夹\n",
    "local_url = './cache/local_data/'\n",
    "if mox.file.exists(local_url):\n",
    "    mox.file.remove(local_url,recursive=True)\n",
    "os.makedirs(local_url)\n",
    "\n",
    "#将私有桶中的数据拷贝到本地mox.file.copy_parallel（）\n",
    "\"\"\"\n",
    "  Copy all files in src_url to dst_url. Same usage as `shutil.copytree`.\n",
    "  Note that this method can only copy a directory. If you want to copy a single file,\n",
    "  please use `mox.file.copy`\n",
    "\n",
    "  Example::\n",
    "\n",
    "    copy_parallel(src_url='/tmp', dst_url='s3://bucket_name/my_data')\n",
    "\n",
    "  Assuming files in `/tmp` are:\n",
    "\n",
    "  * /tmp:\n",
    "      * |- train\n",
    "          * |- 1.jpg\n",
    "          * |- 2.jpg\n",
    "      * |- eval\n",
    "          * |- 3.jpg\n",
    "          * |- 4.jpg\n",
    "\n",
    "  Then files after copy in `s3://bucket_name/my_data` are:\n",
    "\n",
    "  * s3://bucket_name/my_data:\n",
    "      * |- train\n",
    "          * |- 1.jpg\n",
    "          * |- 2.jpg\n",
    "      * |- eval\n",
    "          * |- 3.jpg\n",
    "          * |- 4.jpg\n",
    "\n",
    "  Directory `tmp` will not be copied. If `file_list` is `['train/1.jpg', 'eval/4.jpg']`,\n",
    "  then files after copy in `s3://bucket_name/my_data` are:\n",
    "\n",
    "  * s3://bucket_name/my_data\n",
    "      * |- train\n",
    "          * |- 1.jpg\n",
    "      * |- eval\n",
    "          * |- 4.jpg\n",
    "\n",
    "  :param src_url: Source path or s3 url\n",
    "  :param dst_url: Destination path or s3 url\n",
    "  :param file_list: A list of relative path to `src_url` of files need to be copied.\n",
    "  :param threads: Number of threads or processings in Pool.\n",
    "  :param is_processing: If True, multiprocessing is used. If False, multithreading is used.\n",
    "  :param use_queue: Whether use queue to manage downloading list.\n",
    "  :return: None\n",
    "\"\"\"\n",
    "mox.file.copy_parallel(data_url, local_url)\n",
    "data_url = local_url\n",
    "os.listdir(data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**说明 1**  &#160; &#160; 函数 tf.flags.DEFINE_string('data_url', None, 'Dir of dataset')  数据路径。\n",
    "                  函数tf.flags.DEFINE_string('train_url', None, 'Train Url') 日志以及生产模型的存储路径。 当脚本运行的时候可以利用tf.flags传入参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.flags.DEFINE_string('data_url', None, 'Dir of dataset')\n",
    "tf.flags.DEFINE_string('train_url', None, 'Train Url')\n",
    "\n",
    "flags = tf.flags.FLAGS\n",
    "\n",
    "filenames = ['train-images-idx3-ubyte.gz','train-labels-idx1-ubyte.gz','t10k-images-idx3-ubyte.gz',\n",
    "             't10k-labels-idx1-ubyte.gz']\n",
    "\n",
    "for filename in filenames:\n",
    "  filepath = os.path.join(data_url, filename)\n",
    "  if not mox.file.exists(filepath):\n",
    "    raise ValueError('MNIST dataset file %s not found in %s' % (filepath, local_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  &#160;&#160;训练的main函数包含三个部分，输入定义、模型定义和运行。\n",
    "\n",
    "1） 输入函数：input_fn(run_mode, **kwargs) 用户可以根据自己的输入编写。本例中通过迭代的方式从数据集中取数据。\n",
    "\n",
    "\n",
    "2） 模型定义：def model_fn(inputs, run_mode, **kwargs): 模型结构定义函数，返回 mox.ModelSpec(），用户作业模式定义返回值。\n",
    "但需要满足如下条件：\n",
    "\n",
    " &#160;&#160; For run_mode == ModeKeys.TRAIN: `loss` is required.\n",
    "  \n",
    "  &#160;&#160;  For run_mode == ModeKeys.EVAL: `log_info` is required.\n",
    "  \n",
    "  &#160;&#160;  For run_mode == ModeKeys.PREDICT: `output_info` is required.\n",
    "  \n",
    "  &#160;&#160;  For run_mode == ModeKeys.EXPORT: `export_spec` is required.\n",
    "  \n",
    "\n",
    "3） 执行训练： mox.run(），训练的过程中可指定optimizer的一些设置，训练batch的大小等，设置内容如下：\n",
    "\n",
    "\n",
    " &#160;&#160; 输入函数， input_fn: An input_fn defined by user. Allows tfrecord or python data. Returns  input tensor list.\n",
    " \n",
    " &#160;&#160;  模型函数， model_fn: A model_fn defined by user. Returns `mox.ModelSpec`.\n",
    "  \n",
    "  &#160;&#160; optimizer定义， optimizer_fn: An optimizer_fn defined by user. Returns an optimizer.\n",
    "  \n",
    "  &#160;&#160; 运行模式选择， run_mode: Only takes mox.ModeKeys.TRAIN or mox.ModeKeys.EVAL or mox.ModeKeys.PREDICT\n",
    "  \n",
    "  &#160;&#160; batch大小设置， batch_size: Mini-batch size.\n",
    "  \n",
    " &#160;&#160;  是否自动化batch， auto_batch: If True, an extra dimension of batch_size will be expanded to the first\n",
    "                     dimension of the return value from `get_split`. Default to True.\n",
    "                     \n",
    "  &#160;&#160; 日志以及checkpoint保存位置， log_dir: The directory to save summaries and checkpoints.\n",
    "  \n",
    "  &#160;&#160; 最大数量，  max_number_of_steps: Maximum steps for each worker.\n",
    "                          \n",
    "  &#160;&#160; 日志打印， log_every_n_steps: Step period to print logs to std I/O.\n",
    "     \n",
    "  &#160;&#160; 是否输出模型， export_model: True or False. Where to export model after running the job.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-7fd406f6124a>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./cache/local_data/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./cache/local_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./cache/local_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./cache/local_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/contrib/slim/python/slim/data/prefetch_queue.py:88: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/contrib/slim/python/slim/data/prefetch_queue.py:88: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/contrib/slim/python/slim/data/prefetch_queue.py:90: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-7fd406f6124a>:25: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./cache/log/model.ckpt.\n",
      "INFO:tensorflow:Running will end at step: 50\n",
      "INFO:tensorflow:step: 0(global step: 0)\tsample/sec: 97.193\tloss: 2.303\taccuracy: 0.140\n",
      "INFO:tensorflow:step: 10(global step: 10)\tsample/sec: 21331.489\tloss: 2.196\taccuracy: 0.480\n",
      "INFO:tensorflow:step: 20(global step: 20)\tsample/sec: 24905.869\tloss: 2.113\taccuracy: 0.480\n",
      "INFO:tensorflow:step: 30(global step: 30)\tsample/sec: 27851.780\tloss: 2.026\taccuracy: 0.620\n",
      "INFO:tensorflow:step: 40(global step: 40)\tsample/sec: 25362.382\tloss: 1.950\taccuracy: 0.760\n",
      "INFO:tensorflow:Sync to send FPS to non-chief workers.\n",
      "INFO:tensorflow:Saving checkpoints for 50 into ./cache/log/model.ckpt.\n",
      "WARNING:tensorflow:From <ipython-input-7-7fd406f6124a>:43: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./cache/log/model.ckpt-50\n",
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 50 into ./cache/log/model.ckpt.\n",
      "INFO:tensorflow:Running will end at step: 100\n",
      "INFO:tensorflow:step: 50(global step: 50)\tsample/sec: 493.925\tloss: 1.890\taccuracy: 0.720\n",
      "INFO:tensorflow:step: 60(global step: 60)\tsample/sec: 29733.657\tloss: 1.839\taccuracy: 0.740\n",
      "INFO:tensorflow:step: 70(global step: 70)\tsample/sec: 30407.279\tloss: 1.649\taccuracy: 0.780\n",
      "INFO:tensorflow:step: 80(global step: 80)\tsample/sec: 28920.002\tloss: 1.599\taccuracy: 0.800\n",
      "INFO:tensorflow:step: 90(global step: 90)\tsample/sec: 31782.555\tloss: 1.561\taccuracy: 0.780\n",
      "INFO:tensorflow:Sync to send FPS to non-chief workers.\n",
      "INFO:tensorflow:Saving checkpoints for 100 into ./cache/log/model.ckpt.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./cache/log/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 100 into ./cache/log/model.ckpt.\n",
      "INFO:tensorflow:Running will end at step: 150\n",
      "INFO:tensorflow:step: 100(global step: 100)\tsample/sec: 479.615\tloss: 1.490\taccuracy: 0.900\n",
      "INFO:tensorflow:step: 110(global step: 110)\tsample/sec: 29001.238\tloss: 1.515\taccuracy: 0.800\n",
      "INFO:tensorflow:step: 120(global step: 120)\tsample/sec: 32404.087\tloss: 1.485\taccuracy: 0.740\n",
      "INFO:tensorflow:step: 130(global step: 130)\tsample/sec: 31004.326\tloss: 1.380\taccuracy: 0.800\n",
      "INFO:tensorflow:step: 140(global step: 140)\tsample/sec: 31068.919\tloss: 1.410\taccuracy: 0.640\n",
      "INFO:tensorflow:Sync to send FPS to non-chief workers.\n",
      "INFO:tensorflow:Saving checkpoints for 150 into ./cache/log/model.ckpt.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./cache/log/model.ckpt-150\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 150 into ./cache/log/model.ckpt.\n",
      "INFO:tensorflow:Running will end at step: 200\n",
      "INFO:tensorflow:step: 150(global step: 150)\tsample/sec: 472.104\tloss: 1.370\taccuracy: 0.820\n",
      "INFO:tensorflow:step: 160(global step: 160)\tsample/sec: 28292.101\tloss: 1.317\taccuracy: 0.800\n",
      "INFO:tensorflow:step: 170(global step: 170)\tsample/sec: 29146.086\tloss: 1.325\taccuracy: 0.840\n",
      "INFO:tensorflow:step: 180(global step: 180)\tsample/sec: 30940.002\tloss: 1.255\taccuracy: 0.780\n",
      "INFO:tensorflow:step: 190(global step: 190)\tsample/sec: 30897.267\tloss: 1.202\taccuracy: 0.880\n",
      "INFO:tensorflow:Sync to send FPS to non-chief workers.\n",
      "INFO:tensorflow:Saving checkpoints for 200 into ./cache/log/model.ckpt.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./cache/log/model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 200 into ./cache/log/model.ckpt.\n",
      "INFO:tensorflow:Running will end at step: 1000\n",
      "INFO:tensorflow:step: 200(global step: 200)\tsample/sec: 481.138\tloss: 1.191\taccuracy: 0.820\n",
      "INFO:tensorflow:step: 210(global step: 210)\tsample/sec: 29979.390\tloss: 1.063\taccuracy: 0.820\n",
      "INFO:tensorflow:step: 220(global step: 220)\tsample/sec: 29550.358\tloss: 1.166\taccuracy: 0.760\n",
      "INFO:tensorflow:step: 230(global step: 230)\tsample/sec: 27330.020\tloss: 1.065\taccuracy: 0.880\n",
      "INFO:tensorflow:step: 240(global step: 240)\tsample/sec: 29779.838\tloss: 1.173\taccuracy: 0.740\n",
      "INFO:tensorflow:step: 250(global step: 250)\tsample/sec: 29395.035\tloss: 1.132\taccuracy: 0.820\n",
      "INFO:tensorflow:step: 260(global step: 260)\tsample/sec: 30215.607\tloss: 0.942\taccuracy: 0.840\n",
      "INFO:tensorflow:step: 270(global step: 270)\tsample/sec: 30925.744\tloss: 1.057\taccuracy: 0.780\n",
      "INFO:tensorflow:step: 280(global step: 280)\tsample/sec: 30762.716\tloss: 0.994\taccuracy: 0.760\n",
      "INFO:tensorflow:step: 290(global step: 290)\tsample/sec: 26646.363\tloss: 1.047\taccuracy: 0.800\n",
      "INFO:tensorflow:global_step/sec: 571.232\n",
      "INFO:tensorflow:step: 300(global step: 300)\tsample/sec: 13177.980\tloss: 0.908\taccuracy: 0.860\n",
      "INFO:tensorflow:step: 310(global step: 310)\tsample/sec: 32256.123\tloss: 0.945\taccuracy: 0.780\n",
      "INFO:tensorflow:step: 320(global step: 320)\tsample/sec: 28679.002\tloss: 0.992\taccuracy: 0.820\n",
      "INFO:tensorflow:step: 330(global step: 330)\tsample/sec: 25243.131\tloss: 0.988\taccuracy: 0.780\n",
      "INFO:tensorflow:step: 340(global step: 340)\tsample/sec: 27380.197\tloss: 0.902\taccuracy: 0.880\n",
      "INFO:tensorflow:step: 350(global step: 350)\tsample/sec: 24389.920\tloss: 0.963\taccuracy: 0.760\n",
      "INFO:tensorflow:step: 360(global step: 360)\tsample/sec: 32372.824\tloss: 0.966\taccuracy: 0.820\n",
      "INFO:tensorflow:step: 370(global step: 370)\tsample/sec: 29427.259\tloss: 0.703\taccuracy: 0.960\n",
      "INFO:tensorflow:step: 380(global step: 380)\tsample/sec: 33042.277\tloss: 0.928\taccuracy: 0.800\n",
      "INFO:tensorflow:step: 390(global step: 390)\tsample/sec: 29979.390\tloss: 0.763\taccuracy: 0.940\n",
      "INFO:tensorflow:global_step/sec: 819.294\n",
      "INFO:tensorflow:step: 400(global step: 400)\tsample/sec: 12270.774\tloss: 0.883\taccuracy: 0.800\n",
      "INFO:tensorflow:step: 410(global step: 410)\tsample/sec: 27753.873\tloss: 0.832\taccuracy: 0.840\n",
      "INFO:tensorflow:step: 420(global step: 420)\tsample/sec: 32094.148\tloss: 1.074\taccuracy: 0.780\n",
      "INFO:tensorflow:step: 430(global step: 430)\tsample/sec: 25850.872\tloss: 1.062\taccuracy: 0.780\n",
      "INFO:tensorflow:step: 440(global step: 440)\tsample/sec: 26572.506\tloss: 0.656\taccuracy: 0.920\n",
      "INFO:tensorflow:step: 450(global step: 450)\tsample/sec: 27811.382\tloss: 0.897\taccuracy: 0.800\n",
      "INFO:tensorflow:step: 460(global step: 460)\tsample/sec: 27098.269\tloss: 0.825\taccuracy: 0.820\n",
      "INFO:tensorflow:step: 470(global step: 470)\tsample/sec: 29766.629\tloss: 0.832\taccuracy: 0.840\n",
      "INFO:tensorflow:step: 480(global step: 480)\tsample/sec: 27645.258\tloss: 0.740\taccuracy: 0.880\n",
      "INFO:tensorflow:step: 490(global step: 490)\tsample/sec: 32577.118\tloss: 0.860\taccuracy: 0.840\n",
      "INFO:tensorflow:global_step/sec: 812.066\n",
      "INFO:tensorflow:step: 500(global step: 500)\tsample/sec: 12546.058\tloss: 0.827\taccuracy: 0.780\n",
      "INFO:tensorflow:step: 510(global step: 510)\tsample/sec: 30441.762\tloss: 0.737\taccuracy: 0.820\n",
      "INFO:tensorflow:step: 520(global step: 520)\tsample/sec: 29979.390\tloss: 0.856\taccuracy: 0.780\n",
      "INFO:tensorflow:step: 530(global step: 530)\tsample/sec: 30421.063\tloss: 0.876\taccuracy: 0.820\n",
      "INFO:tensorflow:step: 540(global step: 540)\tsample/sec: 32380.634\tloss: 0.945\taccuracy: 0.760\n",
      "INFO:tensorflow:step: 550(global step: 550)\tsample/sec: 31521.308\tloss: 0.733\taccuracy: 0.840\n",
      "INFO:tensorflow:step: 560(global step: 560)\tsample/sec: 25209.941\tloss: 0.700\taccuracy: 0.920\n",
      "INFO:tensorflow:step: 570(global step: 570)\tsample/sec: 30497.098\tloss: 0.750\taccuracy: 0.840\n",
      "INFO:tensorflow:step: 580(global step: 580)\tsample/sec: 26641.073\tloss: 0.955\taccuracy: 0.800\n",
      "INFO:tensorflow:step: 590(global step: 590)\tsample/sec: 28429.936\tloss: 0.636\taccuracy: 0.960\n",
      "INFO:tensorflow:global_step/sec: 846.576\n",
      "INFO:tensorflow:step: 600(global step: 600)\tsample/sec: 12967.896\tloss: 0.687\taccuracy: 0.880\n",
      "INFO:tensorflow:step: 610(global step: 610)\tsample/sec: 29158.750\tloss: 0.847\taccuracy: 0.800\n",
      "INFO:tensorflow:step: 620(global step: 620)\tsample/sec: 31425.364\tloss: 0.835\taccuracy: 0.800\n",
      "INFO:tensorflow:step: 630(global step: 630)\tsample/sec: 30776.824\tloss: 0.792\taccuracy: 0.840\n",
      "INFO:tensorflow:step: 640(global step: 640)\tsample/sec: 31184.416\tloss: 0.638\taccuracy: 0.920\n",
      "INFO:tensorflow:step: 650(global step: 650)\tsample/sec: 26694.059\tloss: 0.763\taccuracy: 0.880\n",
      "INFO:tensorflow:step: 660(global step: 660)\tsample/sec: 30833.386\tloss: 0.711\taccuracy: 0.840\n",
      "INFO:tensorflow:step: 670(global step: 670)\tsample/sec: 29305.181\tloss: 0.667\taccuracy: 0.900\n",
      "INFO:tensorflow:step: 680(global step: 680)\tsample/sec: 31395.960\tloss: 0.919\taccuracy: 0.800\n",
      "INFO:tensorflow:step: 690(global step: 690)\tsample/sec: 29343.622\tloss: 0.746\taccuracy: 0.780\n",
      "INFO:tensorflow:global_step/sec: 831.266\n",
      "INFO:tensorflow:step: 700(global step: 700)\tsample/sec: 12210.492\tloss: 0.586\taccuracy: 0.920\n",
      "INFO:tensorflow:step: 710(global step: 710)\tsample/sec: 32217.410\tloss: 0.745\taccuracy: 0.840\n",
      "INFO:tensorflow:step: 720(global step: 720)\tsample/sec: 30359.133\tloss: 0.618\taccuracy: 0.920\n",
      "INFO:tensorflow:step: 730(global step: 730)\tsample/sec: 29317.983\tloss: 0.675\taccuracy: 0.860\n",
      "INFO:tensorflow:step: 740(global step: 740)\tsample/sec: 26625.219\tloss: 0.622\taccuracy: 0.920\n",
      "INFO:tensorflow:step: 750(global step: 750)\tsample/sec: 27257.865\tloss: 0.746\taccuracy: 0.800\n",
      "INFO:tensorflow:step: 760(global step: 760)\tsample/sec: 30304.296\tloss: 0.733\taccuracy: 0.860\n",
      "INFO:tensorflow:step: 770(global step: 770)\tsample/sec: 29819.535\tloss: 0.613\taccuracy: 0.900\n",
      "INFO:tensorflow:step: 780(global step: 780)\tsample/sec: 27186.090\tloss: 0.798\taccuracy: 0.840\n",
      "INFO:tensorflow:step: 790(global step: 790)\tsample/sec: 28994.973\tloss: 0.536\taccuracy: 0.880\n",
      "INFO:tensorflow:global_step/sec: 839.475\n",
      "INFO:tensorflow:step: 800(global step: 800)\tsample/sec: 11854.595\tloss: 0.729\taccuracy: 0.880\n",
      "INFO:tensorflow:step: 810(global step: 810)\tsample/sec: 29478.965\tloss: 0.584\taccuracy: 0.860\n",
      "INFO:tensorflow:step: 820(global step: 820)\tsample/sec: 30805.079\tloss: 0.786\taccuracy: 0.800\n",
      "INFO:tensorflow:step: 830(global step: 830)\tsample/sec: 28197.002\tloss: 0.647\taccuracy: 0.800\n",
      "INFO:tensorflow:step: 840(global step: 840)\tsample/sec: 30379.748\tloss: 0.574\taccuracy: 0.940\n",
      "INFO:tensorflow:step: 850(global step: 850)\tsample/sec: 31521.308\tloss: 0.650\taccuracy: 0.900\n",
      "INFO:tensorflow:step: 860(global step: 860)\tsample/sec: 30019.622\tloss: 0.632\taccuracy: 0.860\n",
      "INFO:tensorflow:step: 870(global step: 870)\tsample/sec: 28907.544\tloss: 0.699\taccuracy: 0.880\n",
      "INFO:tensorflow:step: 880(global step: 880)\tsample/sec: 32720.070\tloss: 0.670\taccuracy: 0.840\n",
      "INFO:tensorflow:step: 890(global step: 890)\tsample/sec: 27274.482\tloss: 0.535\taccuracy: 0.920\n",
      "INFO:tensorflow:global_step/sec: 833.999\n",
      "INFO:tensorflow:step: 900(global step: 900)\tsample/sec: 13180.568\tloss: 0.633\taccuracy: 0.900\n",
      "INFO:tensorflow:step: 910(global step: 910)\tsample/sec: 31286.184\tloss: 0.733\taccuracy: 0.800\n",
      "INFO:tensorflow:step: 920(global step: 920)\tsample/sec: 26784.619\tloss: 0.748\taccuracy: 0.840\n",
      "INFO:tensorflow:step: 930(global step: 930)\tsample/sec: 28460.078\tloss: 0.504\taccuracy: 0.940\n",
      "INFO:tensorflow:step: 940(global step: 940)\tsample/sec: 31447.453\tloss: 0.501\taccuracy: 0.900\n",
      "INFO:tensorflow:step: 950(global step: 950)\tsample/sec: 29681.054\tloss: 0.425\taccuracy: 0.940\n",
      "INFO:tensorflow:step: 960(global step: 960)\tsample/sec: 21543.777\tloss: 0.537\taccuracy: 0.900\n",
      "INFO:tensorflow:step: 970(global step: 970)\tsample/sec: 27497.998\tloss: 0.797\taccuracy: 0.760\n",
      "INFO:tensorflow:step: 980(global step: 980)\tsample/sec: 31213.425\tloss: 0.607\taccuracy: 0.840\n",
      "INFO:tensorflow:step: 990(global step: 990)\tsample/sec: 30427.959\tloss: 0.693\taccuracy: 0.820\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into ./cache/log/model.ckpt.\n",
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Ignoring --checkpoint_path because a checkpoint already exists in ./cache/log/\n",
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:Restoring parameters from ./cache/log/model.ckpt-1000\n",
      "INFO:tensorflow:SavedModel written to: ./cache/log/model/saved_model.pb\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main(*args):\n",
    "  flags.data_url = data_url\n",
    "  flags.train_url = train_url\n",
    "  mnist = input_data.read_data_sets(flags.data_url, one_hot=True)\n",
    "        \n",
    "\n",
    "  # define the input dataset, return image and label\n",
    "  def input_fn(run_mode, **kwargs):\n",
    "    def gen():\n",
    "      while True:\n",
    "        yield mnist.train.next_batch(50)\n",
    "    ds = tf.data.Dataset.from_generator(\n",
    "        gen, output_types=(tf.float32, tf.int64),\n",
    "        output_shapes=(tf.TensorShape([None, 784]), tf.TensorShape([None, 10])))\n",
    "    return ds.make_one_shot_iterator().get_next()\n",
    "\n",
    "\n",
    "  # define the model for training or evaling.\n",
    "  def model_fn(inputs, run_mode, **kwargs):\n",
    "    x, y_ = inputs\n",
    "    W = tf.get_variable(name='W', initializer=tf.zeros([784, 10]))\n",
    "    b = tf.get_variable(name='b', initializer=tf.zeros([10]))\n",
    "    y = tf.matmul(x, W) + b\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "    predictions = tf.argmax(y, 1)\n",
    "    correct_predictions = tf.equal(predictions, tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "    export_spec = mox.ExportSpec(inputs_dict={'images': x}, outputs_dict={'predictions': predictions}, version='model')\n",
    "    return mox.ModelSpec(loss=cross_entropy, log_info={'loss': cross_entropy, 'accuracy': accuracy},\n",
    "                         export_spec=export_spec)\n",
    "\n",
    "\n",
    "  mox.run(input_fn=input_fn,\n",
    "          model_fn=model_fn,\n",
    "          optimizer_fn=mox.get_optimizer_fn('sgd', learning_rate=0.01),\n",
    "          run_mode=mox.ModeKeys.TRAIN,\n",
    "          batch_size=32,  # 50\n",
    "          auto_batch=False,\n",
    "          log_dir=flags.train_url,\n",
    "          max_number_of_steps=1000,\n",
    "          log_every_n_steps=10,\n",
    "          export_model=mox.ExportKeys.TF_SERVING)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  tf.app.run(main=main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"predict\">2. 预测</a>  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8195;&#8195; 在上面训练的基础上，我们可以直接用训练的模型进行预测作业。如读取OBS桶中的数字图片进行识别。input_fn 对输入图片进行简单处理，得到网络允许的输入tensor；model_fn定义一个预测内容，同时，还需定义一个对输出处理的函数output_fn，我们在改函数里对输出进行一个打印输出。\n",
    " \n",
    "  还需在 mox.run()函数中加入如下参数：\n",
    "  \n",
    " &#8195;&#8195; 输出函数 output_fn: A callback with args of results from sess.run.\n",
    "   \n",
    "&#8195;&#8195; 模型加载位置 checkpoint_path: Directory or file path of ckpt to restore when `run_mode` is 'evaluation'.\n",
    "                          Useless when `run_mode` is 'train'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### your coding place： begin###########\n",
    "\n",
    "#此处必须修改为用户数据存储的OBS位置\n",
    "\n",
    "# 预测图片在OBS的存储位置。\n",
    "# eg. 图片名称：  image_number.jpg\n",
    "#     存储位置为：bucket/test/\n",
    "src_path = 's3://qyt-mnist-data/train-log/test.jpg'\n",
    "\n",
    "####### your coding place： end  ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以利用moxing 将需要预测的图片从OBS拷贝到本地\n",
    "if not mox.file.exists(src_path):\n",
    "    raise ValueError('Plese verify your src_path!')\n",
    "dst_path =  './cache/test.jpg'\n",
    "mox.file.copy(src_path,dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "image_path = './cache/test.jpg'            # 指定图片位置\n",
    "checkpoint_url = './cache/log/'         # 指定checkpoint位置，即上一步训练指定的路径的位置。\n",
    "print(mox.file.exists(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moxing.tensorflow as mox\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./cache/log/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:\t[1 examples]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result： [7]\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def predict(*args):\n",
    "  def input_fn(run_mode, **kwargs):\n",
    "    image = tf.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(image, channels=1)\n",
    "    img = tf.image.resize_images(img, [28, 28], 0)\n",
    "    img = tf.reshape(img, [784])\n",
    "    return img\n",
    "\n",
    "  def model_fn(inputs, run_mode, **kwargs):\n",
    "    x = inputs\n",
    "    W1 = tf.get_variable(name='W', initializer=tf.zeros([784, 10]))\n",
    "    b1 = tf.get_variable(name='b', initializer=tf.zeros([10]))\n",
    "    y = tf.matmul(x, W1) + b1\n",
    "    predictions = tf.argmax(y, 1)\n",
    "    return mox.ModelSpec(output_info={'predict': predictions})\n",
    "\n",
    "  def output_fn(outputs):\n",
    "    for output in outputs:\n",
    "      result = output['predict']\n",
    "      print(\"The result：\",result)\n",
    "\n",
    "  mox.run(input_fn=input_fn,\n",
    "          model_fn=model_fn,\n",
    "          output_fn=output_fn,\n",
    "          run_mode=mox.ModeKeys.PREDICT,\n",
    "          batch_size=1,\n",
    "          auto_batch=False,\n",
    "          max_number_of_steps=1,\n",
    "          output_every_n_steps=1,\n",
    "          checkpoint_path=checkpoint_url)\n",
    "if __name__ == '__main__':\n",
    "  tf.app.run(main=predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过预测，我们能够看到结果输出。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-1.13.1",
   "language": "python",
   "name": "tensorflow-1.13.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
